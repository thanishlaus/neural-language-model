{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTBpk5LYxIdq",
        "outputId": "631cdd37-3b4a-43d9-d6e2-dad9c5405642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.2.0 in /usr/local/lib/python3.11/dist-packages (2.2.0)\n",
            "Requirement already satisfied: torch_xla==2.2.0 in /usr/local/lib/python3.11/dist-packages (2.2.0)\n",
            "Requirement already satisfied: cloud-tpu-client==0.10 in /usr/local/lib/python3.11/dist-packages (0.10)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.11/dist-packages (0.17.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.17.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.2.0)\n",
            "Requirement already satisfied: portalocker==2.8.2 in /usr/local/lib/python3.11/dist-packages (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (2.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from torch_xla==2.2.0) (1.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from torch_xla==2.2.0) (6.0.2)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from cloud-tpu-client==0.10) (1.8.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.11/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.22.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.2.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.34.1)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.17.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0) (12.5.82)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext) (1.26.4)\n",
            "Requirement already satisfied: torchdata==0.7.1 in /usr/local/lib/python3.11/dist-packages (from torchtext) (0.7.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.1->torchtext) (2.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.4.1)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client->cloud-tpu-client==0.10) (4.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (2024.12.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0) (1.3.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.20.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (5.5.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.2.0 torch_xla==2.2.0 cloud-tpu-client==0.10 torchtext torchvision torchaudio portalocker==2.8.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V8cE0LbonyTW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0260a66-4746-47ce-f5bc-a04643cebfe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1 | Perplexity: 728.97\n",
            "Epoch 2 | Perplexity: 295.86\n",
            "Epoch 3 | Perplexity: 185.81\n",
            "Epoch 4 | Perplexity: 143.35\n",
            "Epoch 5 | Perplexity: 119.63\n",
            "Epoch 6 | Perplexity: 103.55\n",
            "Epoch 7 | Perplexity: 91.58\n",
            "Epoch 8 | Perplexity: 82.31\n",
            "Epoch 9 | Perplexity: 74.59\n",
            "Epoch 10 | Perplexity: 68.29\n",
            "Epoch 11 | Perplexity: 62.85\n",
            "Epoch 12 | Perplexity: 58.32\n",
            "Epoch 13 | Perplexity: 54.27\n",
            "Epoch 14 | Perplexity: 50.68\n",
            "Epoch 15 | Perplexity: 47.63\n",
            "\n",
            " the economy is improving by the <unk> of a market economy in ual shares and has a big impact in actual earnings per share from a year earlier and the yen from the end\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.datasets import PennTreebank\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "train_iter = iter(PennTreebank (split=\"train\"))\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\", \"<pad>\"], min_freq=3)\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "def data_process(raw_text_iter, seq_len=35):\n",
        "    sequences = []\n",
        "    for item in raw_text_iter:\n",
        "        tokens = torch.tensor([vocab[token] for token in tokenizer(item)], dtype=torch.long)\n",
        "        if len(tokens) >= 5:\n",
        "            sequences.append(tokens[:seq_len])\n",
        "    return sequences\n",
        "\n",
        "train_data = data_process(iter(PennTreebank (split=\"train\")))\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch = sorted(batch, key=lambda x: len(x), reverse=True)\n",
        "    original_lengths = [len(seq) for seq in batch]\n",
        "    padded_batch = pad_sequence(batch, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
        "    input_seq = padded_batch[:, :-1]\n",
        "    target_seq = padded_batch[:, 1:]\n",
        "    input_lengths = torch.tensor([l - 1 for l in original_lengths], dtype=torch.long)\n",
        "    return input_seq, target_seq, input_lengths  # Pass corrected lengths to model\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, collate_fn=collate_fn, pin_memory=True)\n",
        "\n",
        "class RNN_LM(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=256, hidden_size=512, num_layers=3, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=vocab[\"<pad>\"])\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, lengths, hidden=None):\n",
        "        embedded = self.dropout(self.embed(src))\n",
        "        packed_input = pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        packed_output, hidden = self.lstm(packed_input, hidden)\n",
        "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
        "\n",
        "        output = self.fc(output)\n",
        "        return output.contiguous(), hidden\n",
        "\n",
        "model = RNN_LM(len(vocab)).to(device)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=vocab[\"<pad>\"])\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "epochs = 15\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data, target, lengths in train_loader:\n",
        "        data, target, lengths = data.to(device), target.to(device), lengths.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output, _ = model(data, lengths)\n",
        "\n",
        "            loss = criterion(output.view(-1, len(vocab)), target.reshape(-1))\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    perplexity = math.exp(total_loss / len(train_loader))\n",
        "    print(f\"Epoch {epoch+1} | Perplexity: {perplexity:.2f}\")\n",
        "\n",
        "def generate_text(seed_text, max_len=50, temperature=1.0, top_k=5):\n",
        "    model.eval()\n",
        "    tokens = [vocab[token] for token in tokenizer(seed_text)]\n",
        "    input_tensor = torch.tensor(tokens).unsqueeze(0).to(device)\n",
        "\n",
        "    generated = tokens\n",
        "    hidden = None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_len):\n",
        "            output, hidden = model(input_tensor, torch.tensor([len(input_tensor[0])]), hidden)\n",
        "            logits = output[:, -1, :] / temperature\n",
        "\n",
        "            top_k_logits, top_k_indices = torch.topk(logits, top_k)\n",
        "            probs = torch.softmax(top_k_logits, dim=-1)\n",
        "            next_token = top_k_indices[0, torch.multinomial(probs, 1).item()].item()\n",
        "\n",
        "            if next_token == vocab[\"<pad>\"]:\n",
        "                break\n",
        "\n",
        "            generated.append(next_token)\n",
        "            input_tensor = torch.cat([input_tensor, torch.tensor([[next_token]]).to(device)], dim=1)\n",
        "\n",
        "    return \" \".join([vocab.lookup_token(idx) for idx in generated])\n",
        "\n",
        "print(\"\\n\",generate_text(\"The economy is improving\", max_len=30))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "YZlo_WtrdiF-",
        "outputId": "63995045-e855-456a-bdf9-74afe10f8c41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.15.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.8)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.7.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.7.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.45.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "\n",
        "# Load the trained model and vocab (assuming they are saved and available)\n",
        "# model = ...\n",
        "# vocab = ...\n",
        "# tokenizer = ...\n",
        "\n",
        "def generate_text(seed_text, max_len=50, temperature=1.0, top_k=5):\n",
        "    model.eval()\n",
        "    tokens = [vocab[token] for token in tokenizer(seed_text)]\n",
        "    input_tensor = torch.tensor(tokens).unsqueeze(0).to(device)\n",
        "\n",
        "    generated = tokens\n",
        "    hidden = None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_len):\n",
        "            output, hidden = model(input_tensor, torch.tensor([len(input_tensor[0])]), hidden)\n",
        "            logits = output[:, -1, :] / temperature\n",
        "\n",
        "            top_k_logits, top_k_indices = torch.topk(logits, top_k)\n",
        "            probs = torch.softmax(top_k_logits, dim=-1)\n",
        "            next_token = top_k_indices[0, torch.multinomial(probs, 1).item()].item()\n",
        "\n",
        "            if next_token == vocab[\"<pad>\"]:\n",
        "                break\n",
        "\n",
        "            generated.append(next_token)\n",
        "            input_tensor = torch.cat([input_tensor, torch.tensor([[next_token]]).to(device)], dim=1)\n",
        "\n",
        "    return \" \".join([vocab.lookup_token(idx) for idx in generated])\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=generate_text,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Seed Text\"),\n",
        "        gr.Slider(10, 100, value=50, label=\"Max Length\"),\n",
        "        gr.Slider(0.5, 2.0, value=1.0, label=\"Temperature\"),\n",
        "        gr.Slider(1, 10, value=5, label=\"Top-K Sampling\")\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"LSTM Language Model\",\n",
        "    description=\"Enter a seed text to generate new text using the trained LSTM model.\"\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "EZpm0rR5dIpv",
        "outputId": "fb5d5082-438c-4afe-a268-f3ed8d6a238b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://42e38d19f08b51ea8c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://42e38d19f08b51ea8c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}